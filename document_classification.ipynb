{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import  Dropout, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "import tika\n",
    "import glob\n",
    "from tika import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"C:\\\\Users\\\\Alex.Chokwijitkul\\\\Desktop\\\\Document Classification\\\\data\\\\\"\n",
    "\n",
    "agenda_paths = [f for f in glob.glob(root_path + \"Agendas/*\", recursive=False)]\n",
    "medicalrecord_paths = [f for f in glob.glob(root_path + \"MedicalRecords/*\", recursive=False)]\n",
    "paper_paths = [f for f in glob.glob(root_path + \"Papers/*\", recursive=False)]\n",
    "resume_paths = [f for f in glob.glob(root_path + \"Resumes/*\", recursive=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    processed = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    processed = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', processed)\n",
    "    processed = re.sub(r'\\s+', ' ', processed)\n",
    "\n",
    "    return processed\n",
    "\n",
    "def process_raw_data(paths, label):\n",
    "    data = {\n",
    "        'Content': [],\n",
    "        'Type': [label] * len(paths)\n",
    "    }\n",
    "    \n",
    "    for path in paths:\n",
    "        print('Processing {}'.format(path))\n",
    "        parsed = parser.from_file(path)\n",
    "        text = preprocess_text(parsed[\"content\"])\n",
    "        data['Content'].append(text)\n",
    "    \n",
    "    return pd.DataFrame(data, columns = ['Content', 'Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agenda_df = process_raw_data(agenda_paths, 'agenda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicalrecord_df = process_raw_data(medicalrecord_paths, 'medicalrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_df = process_raw_data(paper_paths, 'paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df = process_raw_data(resume_paths, 'resume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([agenda_df, medicalrecord_df, paper_df, resume_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(X_train, X_test, num_words=5000):\n",
    "\n",
    "    vectorizer_x = TfidfVectorizer(max_features=MAX_NB_WORDS)\n",
    "    X_train = vectorizer_x.fit_transform(X_train).toarray()\n",
    "    X_test = vectorizer_x.transform(X_test).toarray()\n",
    "\n",
    "    pickle.dump(vectorizer_x, open('vectoriser.pkl','wb'))\n",
    "    print(\"tf-idf with\", str(np.array(X_train).shape[1]), \"features\")\n",
    "\n",
    "    return (X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_DNN_model(shape, num_classes, dropout=0.2):\n",
    "\n",
    "    model = Sequential()\n",
    "    node = 512 # number of nodes\n",
    "    num_layers = 4 # number of  hidden layer\n",
    "    model.add(Dense(node,input_dim=shape,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    for i in range(0, num_layers):\n",
    "        model.add(Dense(node,input_dim=node,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Content'].values\n",
    "y = df['Type'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_y = encoder.transform(y)\n",
    "dummy_y = np_utils.to_categorical(encoded_y)\n",
    "\n",
    "pickle.dump(encoder, open('encoder.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size=0.20, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf with 5000 features\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf, X_test_tfidf = tfidf(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_DNN_model(X_train_tfidf.shape[1], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               2560512   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 3,613,188\n",
      "Trainable params: 3,613,188\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1024 samples, validate on 256 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 1.1066 - accuracy: 0.6035 - val_loss: 0.4237 - val_accuracy: 0.9414\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 1s 886us/step - loss: 0.2135 - accuracy: 0.9404 - val_loss: 0.1244 - val_accuracy: 0.9492\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 1s 885us/step - loss: 0.0664 - accuracy: 0.9883 - val_loss: 0.0410 - val_accuracy: 0.9961\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 1s 866us/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9961\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 1s 924us/step - loss: 2.6663e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9961\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_tfidf, y_train, validation_split=0.2, epochs=5, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 309us/step\n",
      "Test Score: 0.024418415378846703\n",
      "Test Accuracy: 0.996874988079071\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test_tfidf, y_test, verbose=1)\n",
    "\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def tfidf_all(X, num_words=5000):\n",
    "\n",
    "    vectorizer_x = TfidfVectorizer(max_features=num_words)\n",
    "    X = vectorizer_x.fit_transform(X).toarray()\n",
    "\n",
    "    print(\"tf-idf with\", str(np.array(X).shape[1]), \"features\")\n",
    "\n",
    "    return X\n",
    "\n",
    "def DNN_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    node = 512 # number of nodes\n",
    "    nLayers = 4 # number of  hidden layer\n",
    "    model.add(Dense(node,input_dim=5000,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    for i in range(0,nLayers):\n",
    "        model.add(Dense(node,input_dim=node,activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf with 5000 features\n",
      "Epoch 1/5\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.9181 - accuracy: 0.7047\n",
      "Epoch 2/5\n",
      "1280/1280 [==============================] - 1s 764us/step - loss: 0.1255 - accuracy: 0.9492\n",
      "Epoch 3/5\n",
      "1280/1280 [==============================] - 1s 766us/step - loss: 0.0463 - accuracy: 0.9953\n",
      "Epoch 4/5\n",
      "1280/1280 [==============================] - 1s 796us/step - loss: 0.0052 - accuracy: 0.99840s - loss: 0.0058 - accuracy: 0.99\n",
      "Epoch 5/5\n",
      "1280/1280 [==============================] - 1s 781us/step - loss: 2.1363e-04 - accuracy: 1.0000\n",
      "320/320 [==============================] - 0s 386us/step\n",
      "Epoch 1/5\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.9253 - accuracy: 0.7539\n",
      "Epoch 2/5\n",
      "1280/1280 [==============================] - 1s 793us/step - loss: 0.1289 - accuracy: 0.9539\n",
      "Epoch 3/5\n",
      "1280/1280 [==============================] - 1s 794us/step - loss: 0.0331 - accuracy: 0.9961\n",
      "Epoch 4/5\n",
      "1280/1280 [==============================] - 1s 796us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "1280/1280 [==============================] - 1s 785us/step - loss: 2.6754e-04 - accuracy: 1.0000\n",
      "320/320 [==============================] - 0s 362us/step\n",
      "Epoch 1/5\n",
      "1280/1280 [==============================] - 1s 959us/step - loss: 0.9867 - accuracy: 0.7328\n",
      "Epoch 2/5\n",
      "1280/1280 [==============================] - 1s 823us/step - loss: 0.1277 - accuracy: 0.9539\n",
      "Epoch 3/5\n",
      "1280/1280 [==============================] - 1s 876us/step - loss: 0.0366 - accuracy: 0.9992\n",
      "Epoch 4/5\n",
      "1280/1280 [==============================] - 1s 756us/step - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 5/5\n",
      "1280/1280 [==============================] - 1s 781us/step - loss: 0.0025 - accuracy: 0.9992\n",
      "320/320 [==============================] - 0s 362us/step\n",
      "Epoch 1/5\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.9439 - accuracy: 0.8070\n",
      "Epoch 2/5\n",
      "1280/1280 [==============================] - 1s 801us/step - loss: 0.1203 - accuracy: 0.9578\n",
      "Epoch 3/5\n",
      "1280/1280 [==============================] - 1s 777us/step - loss: 0.0312 - accuracy: 0.9969\n",
      "Epoch 4/5\n",
      "1280/1280 [==============================] - 1s 748us/step - loss: 0.0044 - accuracy: 0.9984\n",
      "Epoch 5/5\n",
      "1280/1280 [==============================] - 1s 770us/step - loss: 0.0019 - accuracy: 0.9984\n",
      "320/320 [==============================] - 0s 343us/step\n",
      "Epoch 1/5\n",
      "1280/1280 [==============================] - 1s 984us/step - loss: 0.9537 - accuracy: 0.7250\n",
      "Epoch 2/5\n",
      "1280/1280 [==============================] - 1s 787us/step - loss: 0.1205 - accuracy: 0.9492\n",
      "Epoch 3/5\n",
      "1280/1280 [==============================] - 1s 775us/step - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "1280/1280 [==============================] - 1s 744us/step - loss: 0.0019 - accuracy: 0.9992\n",
      "Epoch 5/5\n",
      "1280/1280 [==============================] - 1s 770us/step - loss: 7.8949e-04 - accuracy: 1.0000\n",
      "320/320 [==============================] - 0s 337us/step\n",
      "Accuracy: 99.56% (0.42%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=5, batch_size=128, verbose=1)\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(estimator, tfidf_all(X), dummy_y, cv=kfold)\n",
    "\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('model.pkl', 'rb'))\n",
    "vectoriser = pickle.load(open('vectoriser.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    processed = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    processed = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', processed)\n",
    "    processed = re.sub(r'\\s+', ' ', processed)\n",
    "\n",
    "    return processed\n",
    "\n",
    "def process_input_data(paths):\n",
    "    data = []\n",
    "    \n",
    "    for path in paths:\n",
    "        print('Processing {}'.format(path))\n",
    "        parsed = parser.from_file(path)\n",
    "        text = preprocess_text(parsed[\"content\"])\n",
    "        data.append(text)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:\\Users\\Alex.Chokwijitkul\\Desktop\\Document Classification\\data\\Papers\\1812.02993.pdf\n"
     ]
    }
   ],
   "source": [
    "agendas = process_input_data([paper_paths[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = vectoriser.transform([agendas[0]]).toarray()\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1045897e-17, 0.0000000e+00, 1.0000000e+00, 2.7391544e-36]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict([vector])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = np.round(prediction[0])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paper'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = encoder.inverse_transform(np.where(prediction == 1))\n",
    "prediction[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
